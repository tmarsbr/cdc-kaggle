# ğŸš€ Guia de InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

Este guia fornece instruÃ§Ãµes detalhadas para configurar e executar o Sistema de CDC (Change Data Capture).

---

## ğŸ“‹ PrÃ©-requisitos

Antes de comeÃ§ar, certifique-se de ter:

- **Python 3.8 ou superior** instalado
- **Git** instalado
- Conta no **Kaggle** (gratuita)
- Conta na **AWS** com acesso ao S3
- Editor de cÃ³digo (recomendado: VS Code)

---

## ğŸ”§ InstalaÃ§Ã£o Passo a Passo

### 1. Clone o RepositÃ³rio

```bash
git clone https://github.com/TeoMeWhy/cdc-kaggle.git
cd cdc-kaggle
```

### 2. Crie um Ambiente Virtual

**Windows:**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**Linux/Mac:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instale as DependÃªncias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 4. Verifique a InstalaÃ§Ã£o

```bash
python -c "import pandas; import boto3; import kaggle; print('Todas as dependÃªncias instaladas com sucesso!')"
```

---

## ğŸ”‘ ConfiguraÃ§Ã£o de Credenciais

### Kaggle API

1. **Acesse sua conta Kaggle**:
   - FaÃ§a login em https://www.kaggle.com
   
2. **Gere o token de API**:
   - VÃ¡ para https://www.kaggle.com/settings
   - Clique em **"Create New API Token"**
   - Um arquivo `kaggle.json` serÃ¡ baixado

3. **Configure o arquivo kaggle.json**:

   **Windows:**
   ```bash
   mkdir %USERPROFILE%\.kaggle
   move kaggle.json %USERPROFILE%\.kaggle\
   ```

   **Linux/Mac:**
   ```bash
   mkdir -p ~/.kaggle
   mv kaggle.json ~/.kaggle/
   chmod 600 ~/.kaggle/kaggle.json
   ```

### AWS S3

1. **Acesse o Console AWS IAM**:
   - FaÃ§a login em https://console.aws.amazon.com/iam/

2. **Crie um novo usuÃ¡rio**:
   - Clique em **"Users"** â†’ **"Add users"**
   - Nome: `cdc-pipeline-user`
   - Access type: **"Programmatic access"**

3. **Configure permissÃµes**:
   - Attach policy: **"AmazonS3FullAccess"** (ou crie uma policy customizada)

4. **Salve as credenciais**:
   - ApÃ³s criar o usuÃ¡rio, salve:
     - Access Key ID
     - Secret Access Key

5. **Crie um bucket S3**:
   ```bash
   aws s3 mb s3://meu-datalake-cdc --region us-east-1
   ```

---

## âš™ï¸ Arquivo de ConfiguraÃ§Ã£o

### 1. Crie o arquivo `.env`

Na raiz do projeto, crie um arquivo `.env`:

```env
# Kaggle API Credentials
KAGGLE_USERNAME=seu_usuario_kaggle
KAGGLE_KEY=sua_chave_kaggle_api

# AWS Credentials
AWS_ACCESS_KEY_ID=sua_aws_access_key_id
AWS_SECRET_ACCESS_KEY=sua_aws_secret_access_key
AWS_REGION=us-east-1

# Opcional: AWS Session Token (para credenciais temporÃ¡rias)
# AWS_SESSION_TOKEN=seu_token_temporario
```

### 2. Configure o arquivo `config.json`

Edite o arquivo `config.json` na raiz do projeto:

```json
{
    "dataset_name": "teocalvo/teomewhy-loyalty-system",
    
    "aws": {
        "bucket": "meu-datalake-cdc",
        "prefix": "raw/loyalty",
        "region": "us-east-1"
    },

    "timer": {
        "unit": "hours",
        "value": 6
    },

    "cleanup": {
        "enabled": true,
        "keep_last_n_cdc_files": 5
    },

    "tables": [
        {
            "name": "clientes",
            "sep": ";",
            "pk": "idCliente",
            "date_field": "DtAtualizacao"
        },
        {
            "name": "produtos",
            "sep": ";",
            "pk": "IdProduto",
            "date_field": ""
        },
        {
            "name": "transacoes",
            "sep": ";",
            "pk": "IdTransacao",
            "date_field": "DtCriacao"
        },
        {
            "name": "transacao_produto",
            "sep": ";",
            "pk": "idTransacaoProduto",
            "date_field": "vlProduto"
        }
    ]
}
```

#### ParÃ¢metros do `config.json`:

| ParÃ¢metro | DescriÃ§Ã£o |
|-----------|-----------|
| `dataset_name` | Nome do dataset no Kaggle (formato: `usuario/dataset`) |
| `aws.bucket` | Nome do bucket S3 onde os dados serÃ£o armazenados |
| `aws.prefix` | Prefixo (pasta) dentro do bucket |
| `aws.region` | RegiÃ£o AWS do bucket |
| `timer.unit` | Unidade de tempo para execuÃ§Ãµes agendadas (`hours`, `minutes`) |
| `timer.value` | Valor numÃ©rico do intervalo |
| `cleanup.enabled` | Habilita limpeza automÃ¡tica de arquivos antigos |
| `cleanup.keep_last_n_cdc_files` | Quantidade de arquivos CDC a manter |
| `tables[].name` | Nome da tabela/arquivo CSV |
| `tables[].sep` | Separador usado no CSV (`;` ou `,`) |
| `tables[].pk` | Campo que serve como Primary Key |
| `tables[].date_field` | Campo de data/timestamp para detecÃ§Ã£o de mudanÃ§as |

---

## ğŸ§ª Teste a ConfiguraÃ§Ã£o

### 1. Teste as credenciais Kaggle

```bash
python -c "from kaggle.api.kaggle_api_extended import KaggleApi; api = KaggleApi(); api.authenticate(); print('Kaggle OK!')"
```

### 2. Teste as credenciais AWS

```bash
python -c "import boto3; s3 = boto3.client('s3'); print('AWS OK! Buckets:', [b['Name'] for b in s3.list_buckets()['Buckets'][:3]])"
```

### 3. Execute o pipeline em modo de teste

```bash
python main.py
```

---

## ğŸ“ Estrutura de DiretÃ³rios

ApÃ³s a primeira execuÃ§Ã£o, a seguinte estrutura serÃ¡ criada:

```
cdc-kaggle/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ actual/              # Dados atuais baixados do Kaggle
â”‚   â”‚   â”œâ”€â”€ clientes.csv
â”‚   â”‚   â”œâ”€â”€ produtos.csv
â”‚   â”‚   â””â”€â”€ transacoes.csv
â”‚   â”œâ”€â”€ last/                # Snapshot anterior (para comparaÃ§Ã£o CDC)
â”‚   â”‚   â”œâ”€â”€ clientes.csv
â”‚   â”‚   â”œâ”€â”€ produtos.csv
â”‚   â”‚   â””â”€â”€ transacoes.csv
â”‚   â””â”€â”€ cdc/                 # Arquivos CDC gerados (Parquet)
â”‚       â”œâ”€â”€ clientes_20251004_095645.parquet
â”‚       â”œâ”€â”€ produtos_20251004_095646.parquet
â”‚       â””â”€â”€ transacoes_20251004_095647.parquet
â”œâ”€â”€ docs/                    # DocumentaÃ§Ã£o
â”œâ”€â”€ .venv/                   # Ambiente virtual (nÃ£o versionado)
â”œâ”€â”€ .env                     # Credenciais (nÃ£o versionado)
â”œâ”€â”€ config.json              # ConfiguraÃ§Ãµes do pipeline
â”œâ”€â”€ main.py                  # Script principal
â””â”€â”€ requirements.txt         # DependÃªncias Python
```

---

## ğŸ¯ Modos de ExecuÃ§Ã£o

### ExecuÃ§Ã£o Ãšnica

Execute o pipeline uma vez:

```bash
python main.py
```

### ExecuÃ§Ã£o Agendada (Loop)

Execute o pipeline continuamente com intervalo configurado:

```bash
python main.py --schedule
```

Para parar a execuÃ§Ã£o: `Ctrl + C`

### Agendamento no Windows Task Scheduler

Veja as instruÃ§Ãµes completas em [`docs/AGENDAMENTO.md`](AGENDAMENTO.md).

---

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro: "Kaggle credentials not found"

**SoluÃ§Ã£o:**
1. Verifique se o arquivo `kaggle.json` estÃ¡ em `~/.kaggle/` (Linux/Mac) ou `%USERPROFILE%\.kaggle\` (Windows)
2. Verifique as permissÃµes do arquivo (deve ser 600 no Linux/Mac)

### Erro: "Could not connect to AWS"

**SoluÃ§Ã£o:**
1. Verifique se as variÃ¡veis de ambiente estÃ£o configuradas no `.env`
2. Execute: `aws configure` para configurar credenciais via AWS CLI
3. Verifique se o usuÃ¡rio IAM tem permissÃµes no S3

### Erro: "No module named 'pandas'"

**SoluÃ§Ã£o:**
```bash
pip install --upgrade -r requirements.txt
```

### Erro: "Permission denied" ao escrever em data/

**SoluÃ§Ã£o:**
1. Verifique permissÃµes das pastas
2. Execute como administrador (Windows) ou com `sudo` (Linux/Mac)

---

## ğŸ“Š VerificaÃ§Ã£o de Dados

### Verificar arquivos locais

```bash
# Listar arquivos CDC gerados
ls data/cdc/

# Ver conteÃºdo de um arquivo Parquet
python -c "import pandas as pd; print(pd.read_parquet('data/cdc/clientes_20251004_095645.parquet').head())"
```

### Verificar dados no S3

```bash
# Listar arquivos no bucket
aws s3 ls s3://meu-datalake-cdc/raw/loyalty/cdc/

# Baixar um arquivo para anÃ¡lise
aws s3 cp s3://meu-datalake-cdc/raw/loyalty/cdc/clientes_20251004_095645.parquet ./
```

---

## ğŸ”’ SeguranÃ§a

### Boas PrÃ¡ticas

1. **Nunca commit credenciais**: O `.env` jÃ¡ estÃ¡ no `.gitignore`
2. **Use IAM Roles**: Em produÃ§Ã£o, prefira IAM Roles ao invÃ©s de chaves estÃ¡ticas
3. **Rotate credentials**: Renove suas credenciais AWS periodicamente
4. **Least privilege**: DÃª apenas as permissÃµes necessÃ¡rias ao usuÃ¡rio IAM
5. **Encryption**: Configure encryption at rest no S3

---

## ğŸ“š PrÃ³ximos Passos

ApÃ³s configurar o sistema:

1. âœ… Execute o pipeline manualmente para testar
2. âœ… Verifique os logs em `cdc_pipeline.log`
3. âœ… Confirme os uploads no S3
4. âœ… Configure agendamento automÃ¡tico (opcional)
5. âœ… Monitore a primeira execuÃ§Ã£o agendada

---

## ğŸ“ Suporte

- **Issues**: Abra uma issue no [GitHub](https://github.com/TeoMeWhy/cdc-kaggle/issues)
- **Email**: contato@exemplo.com
- **DocumentaÃ§Ã£o**: Consulte o [README principal](../README.md)

---

**ğŸ‰ Pronto! Seu ambiente estÃ¡ configurado e pronto para uso.**
